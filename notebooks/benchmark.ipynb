{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "\n",
    "First, install Gretel Trainer to use Benchmark. Depending on how big your datasets are and how many models and datasets you add, your Benchmark job may take more than 15 min or even longer to run. \n",
    "\n",
    "For best results, try the sample datasets in this notebook first to see Benchmark in action. The \"iris\" and \"heart_disease\" publicly available datasets used in this demo will take between 3 to 10min to finish training on the GretelLSTM and GretelAmplify models.\n",
    "\n",
    "Note: you can always check the progress of the models (and check model training logs) by viewing the Benchmark projects in the Gretel console dashboard. \n",
    "\n",
    "Interested in seeing the results of all Benchmark datasets on all Gretel models? You can check out the Benchmark report here: https://docs.gretel.ai/reference/benchmark/benchmark-report  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U gretel-trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running in Colab, the `pip install` command above will update the `matplotlib` library under the hood, but the previously installed version has already been imported automatically by Colab. As `pip`'s log output should suggest, you need to restart the Colab runtime to use the new version (and, by extension, import and use Benchmark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gretel_trainer.benchmark as b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From your own data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running in Google Colab? You can add your files to Colab file system, like: \"/content/my_files/data.csv\"\n",
    "\n",
    "When using \"make_dataset\", indicate the datatype (select between: \"tabular_mixed\", \"tabular_numeric\", \"natural_language\", and \"time_series\"). Learn more in the [Benchmark docs](https://docs.gretel.ai/reference/benchmark#docs-internal-guid-31c7e29f-7fff-7936-54f8-737618a7e7f3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = b.make_dataset([\"/PATH/TO/MY_DATASET.csv\"], datatype=\"INDICATE_DATATYPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Gretel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to use public data? Gretel makes it easy for you to use common used, publicly available datasets, rather than using your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "datasets = b.list_gretel_datasets() # selects all Benchmark datasets\n",
    "\n",
    "# Other sample commands\n",
    "# datasets = b.list_gretel_datasets(datatype=\"time_series\") # select all time-series datasets\n",
    "# datasets = b.list_gretel_datasets(datatype=\"tabular_mixed\", tags=[\"small\", \"marketing\"]) # select all tabular_mixed, size small, and marketing-related datasets\n",
    "\n",
    "# This will show you all the datasets in the Benchmark dataset bucket\n",
    "[dataset.name for dataset in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark datasets are annotated with tags, so you can select based on your use case\n",
    "b.list_gretel_dataset_tags() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo, we will select two datasets by name:\n",
    "# \"iris.csv\" - a publicly available dataset for predicting the class of the iris plant based on attributes\n",
    "# \"processed_cleveland_heart_disease_uci.csv\" - a publicly available dataset for predicting presence of heart disease\n",
    "iris = b.get_gretel_dataset(\"iris\")\n",
    "heart_disease = b.get_gretel_dataset(\"processed_cleveland_heart_disease_uci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gretel defaults\n",
    "\n",
    "Preconfigured based on [public blueprints](https://github.com/gretelai/gretel-blueprints/tree/main/config_templates/gretel/synthetics). This is the easiest way to use Gretel's models out-of-the-box with the default configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_trainer.benchmark import (\n",
    "    GretelAmplify,\n",
    "    GretelAuto,\n",
    "    GretelACTGAN,\n",
    "    GretelGPTX,\n",
    "    GretelLSTM,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Gretel models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also cusotmize Gretel models by changing the config to your customized configuration YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_trainer.benchmark import GretelModel\n",
    "\n",
    "# If trying in Colab: remember to add your config file to Colab's local file storage, then indicate the path like: \"/content/my_files/my_config.yml\"\n",
    "class MyCustomLSTM(GretelModel):\n",
    "    config = \"/PATH/TO/MY_CONFIG.yml\"\n",
    "\n",
    "\n",
    "class MyCustomACTGAN(GretelModel):\n",
    "    config = {...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completely custom, non-Gretel models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark lets you compare any model, not just Gretel models. You can implement any custom in Python. Learn more in the [Benchmark documentation](https://docs.gretel.ai/reference/benchmark#docs-internal-guid-31c7e29f-7fff-7936-54f8-737618a7e7f3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MyCustomModel:\n",
    "    def train(self, source: str, **kwargs) -> None:\n",
    "        self.source_df = pd.read_csv(source)\n",
    "        time.sleep(8)\n",
    "        return None\n",
    "\n",
    "    def generate(self, **kwargs) -> pd.DataFrame:\n",
    "        time.sleep(3)\n",
    "        return self.source_df.sample(frac=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a Benchmark Comparison!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together! \n",
    "\n",
    "In any one Benchmark comparison: only run with datasets that are of the same datatype. Tip: make sure the models you select are applicable to the datatype of the datasets. \n",
    "\n",
    "Learn more in the Benchmark docs: https://docs.gretel.ai/reference/benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = b.compare(datasets= [heart_disease, iris], models=[GretelLSTM, GretelAmplify])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to see a snapshot of results! (While comparison is running)\n",
    "comparison.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to wait for comparison to finish running, and export results as CSV at the end\n",
    "comparison.wait()\n",
    "comparison.export_results(\"./results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gretel_trainer.benchmark as b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('3.9.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8726cf33f00e2373738d19e8a73b26d03723d6c732c72211354be2991192c77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
