{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "\n",
    "Install Gretel Trainer to use Benchmark. Depending on how big your datasets are and how many models and datasets you add, your Benchmark job may take more than 15 min or even longer to run. \n",
    "\n",
    "For best results, try the sample datasets in this notebook first to see Benchmark in action. The \"iris\" and \"heart_disease\" publicly available datasets used in this demo will take between 10 to 15 minutes to finish training on the GretelLSTM and GretelAmplify models.\n",
    "\n",
    "Note: you can always check the progress of the models (and check model training logs) by viewing the Benchmark projects in the Gretel console dashboard. \n",
    "\n",
    "Interested in seeing the results of all Benchmark datasets on all Gretel models? You can check out the Benchmark report here: https://docs.gretel.ai/reference/benchmark/benchmark-report  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U gretel-trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running in Colab, the `pip install` command above will update the `matplotlib` library under the hood, but the previously installed version has already been imported automatically by Colab. As `pip`'s log output should suggest, you need to restart the Colab runtime to use the new version (and, by extension, import and use Benchmark)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also optionally configure your Gretel credentials here or be prompted when you run the Benchmark comparison later in this notebook. \n",
    "Learn more about signing up for a [free Gretel account](https://docs.gretel.ai/quickstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gretel_trainer.benchmark as b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From your own data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When using your own data, indicate the datatype (select between: \"tabular_mixed\", \"tabular_numeric\", \"natural_language\", and \"time_series\"). Learn more in the [Benchmark docs](https://docs.gretel.ai/reference/benchmark#docs-internal-guid-31c7e29f-7fff-7936-54f8-737618a7e7f3).\n",
    "\n",
    "Running in Google Colab? You can add your files to the Colab file system, and indicate the path like: \"/content/my_files/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_data = b.make_dataset([\"/PATH/TO/MY_DATASET.csv\"], datatype=\"INDICATE_DATATYPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Gretel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to use public data? Gretel makes it easy for you to use common used, publicly available datasets, rather than using your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "datasets = b.list_gretel_datasets() # selects all Benchmark datasets\n",
    "\n",
    "# Other sample commands\n",
    "# datasets = b.list_gretel_datasets(datatype=\"time_series\") # select all time-series datasets\n",
    "# datasets = b.list_gretel_datasets(datatype=\"tabular_mixed\", tags=[\"small\", \"marketing\"]) # select all tabular_mixed, size small, and marketing-related datasets\n",
    "\n",
    "# This will show you all the datasets in the Benchmark dataset bucket\n",
    "[dataset.name for dataset in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark datasets are annotated with tags, so you can select based on your use case\n",
    "b.list_gretel_dataset_tags() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo, we will select two datasets by name:\n",
    "# \"iris.csv\" - a publicly available dataset for predicting the class of the iris plant based on attributes\n",
    "# \"processed_cleveland_heart_disease_uci.csv\" - a publicly available dataset for predicting presence of heart disease\n",
    "iris = b.get_gretel_dataset(\"iris\")\n",
    "heart_disease = b.get_gretel_dataset(\"processed_cleveland_heart_disease_uci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gretel defaults\n",
    "\n",
    "Preconfigured based on [public blueprints](https://github.com/gretelai/gretel-blueprints/tree/main/config_templates/gretel/synthetics). This is the easiest way to use Gretel's models out-of-the-box with the default configurations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_trainer.benchmark import (\n",
    "    GretelAmplify,\n",
    "    GretelAuto,\n",
    "    GretelACTGAN,\n",
    "    GretelGPTX,\n",
    "    GretelLSTM,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Gretel models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also cusotmize Gretel models by changing the config to your customized configuration YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from gretel_trainer.benchmark import GretelModel\n",
    "\n",
    "# If trying in Colab: remember to add your config file to Colab's local file storage, then indicate the path like: \"/content/my_files/my_config.yml\"\n",
    "class MyCustomLSTM(GretelModel):\n",
    "    config = \"/PATH/TO/MY_CONFIG.yml\"\n",
    "\n",
    "\n",
    "class MyCustomACTGAN(GretelModel):\n",
    "    config = {...}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completely custom, non-Gretel models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmark lets you compare any model, not just Gretel models. You can implement any custom in Python. Learn more in the [Benchmark documentation](https://docs.gretel.ai/reference/benchmark#docs-internal-guid-31c7e29f-7fff-7936-54f8-737618a7e7f3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class MyCustomModel:\n",
    "    def train(self, source: str, **kwargs) -> None:\n",
    "        # your training code here\n",
    "    def generate(self, **kwargs) -> pd.DataFrame:\n",
    "        # your generation code here\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch a Benchmark Comparison!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together! \n",
    "\n",
    "When you run a Benchmark comparison, all selected models will run on all indicated datasets. Tip: make sure the models you select are applicable to the datatype of the datasets. \n",
    "\n",
    "Learn more in the Benchmark docs: https://docs.gretel.ai/reference/benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = b.compare(datasets= [heart_disease, iris], models=[GretelLSTM, GretelAmplify])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to see a snapshot of results! (While comparison is running)\n",
    "comparison.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to wait for comparison to finish running, and export results as CSV at the end\n",
    "comparison.wait()\n",
    "comparison.export_results(\"./results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (default, Sep  8 2022, 12:24:54) [Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1264641a2296bed54b65447ff0d3f452674f070f0748798274bc429fe6ce8efd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
