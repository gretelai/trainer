{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultiTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-to-end synthetics example\n",
    "\n",
    "from gretel_trainer.relational import MultiTable, sqlite_conn\n",
    "\n",
    "\n",
    "!curl -o \"ecom_xf.db\" \"https://gretel-blueprints-pub.s3.us-west-2.amazonaws.com/rdb/ecom_xf.db\"\n",
    "\n",
    "\n",
    "connector = sqlite_conn(\"ecom_xf.db\")\n",
    "relational_data = connector.extract()\n",
    "\n",
    "mt = MultiTable(relational_data)\n",
    "mt.train()\n",
    "mt.generate()\n",
    "\n",
    "connector.save(mt.synthetic_output_tables, prefix=\"synthetic_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed walkthrough"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up source relational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the schema of our demo database\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(\"https://gretel-blueprints-pub.s3.us-west-2.amazonaws.com/rdb/ecommerce_db.png\", width=600, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the demo database\n",
    "\n",
    "!curl -o \"ecom_xf.db\" \"https://gretel-blueprints-pub.s3.us-west-2.amazonaws.com/rdb/ecom_xf.db\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core Python object capturing source relational data and metadata is named `RelationalData`.\n",
    "It can be created automatically using a `Connector`, or it can be created manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database and extract relational data\n",
    "\n",
    "from gretel_trainer.relational import sqlite_conn\n",
    "\n",
    "ecommerce_db_path = \"ecom_xf.db\"\n",
    "\n",
    "sqlite = sqlite_conn(path=ecommerce_db_path)\n",
    "relational_data = sqlite.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, manually define relational data\n",
    "\n",
    "from gretel_trainer.relational import RelationalData\n",
    "import pandas as pd\n",
    "\n",
    "csv_dir = \"/path/to/extracted_csvs\"\n",
    "\n",
    "tables = [\n",
    "    (\"events\", \"id\"),\n",
    "    (\"users\", \"id\"),\n",
    "    (\"distribution_center\", \"id\"),\n",
    "    (\"products\", \"id\"),\n",
    "    (\"inventory_items\", \"id\"),\n",
    "    (\"order_items\", \"id\"),\n",
    "]\n",
    "\n",
    "foreign_keys = [\n",
    "    (\"events.user_id\", \"users.id\"),\n",
    "    (\"order_items.user_id\", \"users.id\"),\n",
    "    (\"order_items.inventory_item_id\", \"inventory_items.id\"),\n",
    "    (\"inventory_items.product_id\", \"products.id\"),\n",
    "    (\"inventory_items.product_distribution_center_id\", \"distribution_center.id\"),\n",
    "    (\"products.distribution_center_id\", \"distribution_center.id\"),\n",
    "]\n",
    "\n",
    "rel_data = RelationalData()\n",
    "\n",
    "for table, primary_key in tables:\n",
    "    rel_data.add_table(table, primary_key, pd.read_csv(f\"{csv_dir}/{table}.csv\"))\n",
    "\n",
    "for fk, referencing in foreign_keys:\n",
    "    rel_data.add_foreign_key(fk, referencing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operate on the source data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MultiTable` class is the interface to working with relational data. It requires a `RelationalData` instance. Several other options can be configured; the defaults are shown below as comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_trainer.relational import MultiTable\n",
    "\n",
    "multitable = MultiTable(\n",
    "    relational_data,\n",
    "    # project_name=\"multi-table\",\n",
    "    # working_dir=\"multi-table\", # matches the projet name by default\n",
    "    # gretel_model=\"amplify\",\n",
    "    # strategy=\"cross-table\",\n",
    "    # refresh_interval=180,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforms\n",
    "\n",
    "Provide Gretel Transforms configs for each table you want to run transforms on. If you intend to train synthetic models on the transformed output instead of the source data, add the argument `in_place=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform some tables\n",
    "\n",
    "multitable.transform(\n",
    "    configs={\n",
    "        \"users\": \"https://gretel-blueprints-pub.s3.amazonaws.com/rdb/users_policy.yaml\",\n",
    "        \"events\": \"https://gretel-blueprints-pub.s3.amazonaws.com/rdb/events_policy.yaml\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original to transformed\n",
    "\n",
    "print(multitable.relational_data.get_table_data(\"users\").head(5))\n",
    "print(multitable.transform_output_tables[\"users\"].head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throughout the synthetics process, there are a few ways to inspect the overall state\n",
    "\n",
    "multitable.train_statuses\n",
    "multitable.generate_statuses\n",
    "multitable.state_by_action\n",
    "multitable.state_by_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train synthetic models for all tables\n",
    "\n",
    "multitable.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training is complete, you'll find a number of artifacts in your working directory, including the CSVs on which models were trained (`train_{table}.csv`) and the standard Gretel model artifacts, including HTML and JSON reports and logs (`artifacts_{table}/`).\n",
    "\n",
    "You can also view some evaluation metrics at this point. (We'll expand upon them after generating synthetic data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitable.evaluations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you generate synthetic data, you can optionally change the amount of data to generate via `record_size_ratio`, as well as optionally preserve certain tables' source data via `preserve_tables`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "\n",
    "multitable.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original to synthetic data\n",
    "\n",
    "print(multitable.relational_data.get_table_data(\"user\").head(5))\n",
    "print(multitable.synthetic_output_tables[\"user\"].head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have synthetic output data, we can expand the table evaluations to provide another perspective on synthetic data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitable.expand_evaluations()\n",
    "multitable.evaluations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the data we need to create a full multitable report that summarizes and explains all this information. After running the cell below you'll find `multitable_report.html` in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_trainer.relational import create_report\n",
    "\n",
    "create_report(multitable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from smart_open import open\n",
    "\n",
    "report_path = str(multitable._working_dir / \"multitable_report.html\")\n",
    "\n",
    "IPython.display.HTML(data=open(report_path).read())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The synthetic data is automatically written to the working directory as `synth_{table}.csv`. You can optionally use a `Connector` to write the synthetic data to a database. (If you're writing back to the same database as your source, pass a `prefix: str` argument to the `save` method to avoid overwriting your source tables!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write output data to a new SQLite database\n",
    "\n",
    "from gretel_trainer.relational import sqlite_conn\n",
    "\n",
    "synthetic_db_path = \"out.db\"\n",
    "\n",
    "synthetic_db_conn = sqlite_conn(synthetic_db_path)\n",
    "synthetic_db_conn.save(multitable.synthetic_output_tables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postgres demo via Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start up a postgres container with docker\n",
    "\n",
    "!docker run --rm -d --name multitable_pgdemo -e POSTGRES_PASSWORD=password -p 5432:5432 postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write synthetic tables to the Postgres db\n",
    "\n",
    "from gretel_trainer.relational import postgres_conn\n",
    "\n",
    "out_db = postgres_conn(\"postgres\", \"password\", \"localhost\", 5432)\n",
    "out_db.save(multitable.synthetic_output_tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the postgres database\n",
    "\n",
    "!docker exec multitable_pgdemo psql -U postgres -c \"\\dt\"\n",
    "!docker exec multitable_pgdemo psql -U postgres -c \"select * from users limit 5;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tear down the docker container\n",
    "\n",
    "!docker stop multitable_pgdemo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('3.9.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 (main, May 17 2022, 13:39:35) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8726cf33f00e2373738d19e8a73b26d03723d6c732c72211354be2991192c77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
